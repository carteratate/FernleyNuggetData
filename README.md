# Fernley Nugget Data Project

## Overview
This repository contains exploratory notebooks and Python scripts used to process slot machine meter data from the Fernley Nugget casino.  The workflow cleans raw CSV exports, engineers spatial features, trains predictive models of machine "coin-in" performance, and generates visual analyses of possible floor layouts.

All scripts assume that input and output CSV files live inside a local `Data/` folder in the project root.  Example files referenced throughout the code include:

- `assetmeters 07-25-2025.csv` and `TTgames00 07-25-2025.csv`
- `clustered_coordinates.csv` produced by `spatial_clustering.py`
- `features.csv` produced by `feat_create.py`
- `future_month_layout.csv` produced by `feat_month_extend.py`

## Setup
1. Create a Python 3 environment.
2. Install the required libraries with `pip`:
   ```bash
   pip install pandas numpy matplotlib scikit-learn xgboost lightgbm shap
   ```
3. Place the raw casino meter exports inside the `Data/` directory.

## Preprocessing
The following scripts transform the raw data into usable features:
```bash
# Merge session and machine data
python ctdata_prep.py

# Cluster machine coordinates and save Data/clustered_coordinates.csv
python spatial_clustering.py

# Create training features Data/features.csv
python feat_create.py

# Build a layout for the next month
python feat_month_extend.py
```

## Model Training
Train models that predict machine coin-in values:
```bash
# Random forest baseline
python rf_training.py

# Nonlinear models (RandomForest, LightGBM, XGBoost)
python nonlinear_model_training.py

# Regularized linear model
python elastic_net_training.py
```

## Analyses and Optimization
Once models are trained you can perform additional analyses:
```bash
# SHAP feature importance plot
python shap_analysis.py

# Predict coin-in for a future layout
python predicted_coinin.py

# Optimize future layout with a greedy search
python greedy_swap.py

# Optimize using simulated annealing
python sim_anneal.py
```
Each script reads and writes files inside `Data/` and will overwrite any existing output with the same name.

## SHAP Analysis
The `shap_analysis.py` script computes SHAP feature importances for the `RandomForestRegressor` used in this project. It loads the dataset created in `feat_create.py` and read in `rf_training.py`.
Data loading in the training script occurs at lines 8‑11:
```python
df = pd.read_csv("Data/features.csv")
y = df["coinin"]
X = df.drop(columns=["coinin"])
```
These features are generated by `feat_create.py` at lines 146‑157 before being saved to `Data/features.csv`.
Spatial-related columns such as `x`, `y`, `near_main_door`, and the `is_cluster*` indicators are engineered around lines 64‑88 in `feat_create.py`. The SHAP analysis script highlights these fields separately so you can gauge how a machine's location affects the model.
To run the SHAP analysis and open the summary plot, execute:
```bash
python shap_analysis.py
```
